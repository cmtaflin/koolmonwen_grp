{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "import pandas as pd\n",
    "import json\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "Base = declarative_base()\n",
    "from sqlalchemy import Column, Integer, String, Float, Date\n",
    "import pymysql\n",
    "pymysql.install_as_MySQLdb()\n",
    "from sqlalchemy import create_engine, inspect, func, distinct\n",
    "from sqlalchemy.ext.automap import automap_base\n",
    "from sqlalchemy.orm import Session\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlite3 import Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create function to try and connect to a sqlite database.  if it doesn't work, create one...\n",
    "def create_connection(db_file):\n",
    "    try:\n",
    "        conn = sqlite3.connect(db_file)\n",
    "        print(sqlite3.version)\n",
    "    except Error as e:\n",
    "        print(e)\n",
    "    finally:\n",
    "        conn.close()\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    create_connection(\"..\\db\\happiness.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(\"sqlite:///../db/happiness.db\")\n",
    "conn = engine.connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The section below processes the happiness CSV files into SQLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in happiness files for all years\n",
    "happiness_file_15 = \"happiness_2015.csv\"\n",
    "happy15_df = pd.read_csv(happiness_file_15)\n",
    "\n",
    "happiness_file_16 = \"happiness_2016.csv\"\n",
    "happy16_df = pd.read_csv(happiness_file_16)\n",
    "\n",
    "happiness_file_17 = \"happiness_2017.csv\"\n",
    "happy17_df = pd.read_csv(happiness_file_17)\n",
    "\n",
    "# read in region and continents data\n",
    "region_cont = \"region_continent.csv\"\n",
    "region_cont_df = pd.read_csv(region_cont)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create YEAR and UNIQUE_ID fields\n",
    "# 2015\n",
    "happy15_df['YEAR'] = 2015\n",
    "happy15_df['UNIQUE_ID'] = happy15_df['COUNTRY'] + '_' + happy15_df.YEAR.map(str)\n",
    "\n",
    "# 2016\n",
    "happy16_df['YEAR'] = 2016\n",
    "happy16_df['UNIQUE_ID'] = happy16_df['COUNTRY'] + '_' + happy16_df.YEAR.map(str)\n",
    "\n",
    "# 2017\n",
    "happy17_df['YEAR'] = 2017\n",
    "happy17_df['UNIQUE_ID'] = happy17_df['COUNTRY'] + '_' + happy17_df.YEAR.map(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge to capture Region and Continent data\n",
    "happy15_region_df = pd.merge(happy15_df, region_cont_df, on=\"COUNTRY\")\n",
    "happy16_region_df = pd.merge(happy16_df, region_cont_df, on=\"COUNTRY\")\n",
    "happy17_region_df = pd.merge(happy17_df, region_cont_df, on=\"COUNTRY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set index\n",
    "happy15_region_df.set_index(\"UNIQUE_ID\", inplace=True)\n",
    "happy16_region_df.set_index(\"UNIQUE_ID\", inplace=True)\n",
    "happy17_region_df.set_index(\"UNIQUE_ID\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all year DF's into one DF\n",
    "happyall_region_df = pd.concat([happy15_region_df, happy16_region_df, happy17_region_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reorder fields for final output\n",
    "all_cols = ['YEAR','COUNTRY','REGION','CONTINENT','HAPPINESS_RANK','HAPPINESS_SCORE','ECONOMY_GDP_PER_CAPITA',\n",
    "                      'FAMILY','HEALTH_LIFE_EXPECTANCY','FREEDOM','GENEROSITY','TRUST_GOVERNMENT_CORRUPTION','DYSTOPIA_RESIDUAL']\n",
    "happyall_region_df2= happyall_region_df[all_cols].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-13-1d00789fc396>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-13-1d00789fc396>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    group_export.to_sql(conn=, name=happiness_by_region_yr, if_exists='replace',\u001b[0m\n\u001b[1;37m                             ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "group_export.to_sql(conn, name=happiness_by_region_yr, if_exists='replace',\n",
    "                   flavor='mysql', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load final df into sqlite database\n",
    "happyall_region_df2.to_sql('happiness_by_region_yr', conn, if_exists='replace', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine.connect() as con:\n",
    "   con.execute('ALTER TABLE `example_table` ADD PRIMARY KEY (`ID_column`);')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.read_sql('select * from happiness_by_region_yr', conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in region continent lookup table\n",
    "regions = pd.read_csv(\"region_continent.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load final lookup table into sqlite database\n",
    "regions.to_sql('region_continent', conn, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "social_progress = pd.read_csv(\"SocialProgress.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load Social Progress table into sqlite database\n",
    "social_progress.to_sql('social_progress', conn, if_exists='replace', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine.table_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
